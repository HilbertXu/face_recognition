# 机器智能大作业----人脸识别系统代码报告

​                                                          1611453 徐宇成

​                                                           2019年1月18日

## 目录

### 第一部分 环境配置

#### 1. ubuntu 与 python虚拟环境的配置

#### 2. CUDA 与 CUDNN的配置（Nvidia GPU only）

### 第二部分 人脸识别系统的原理以及使用工具

#### 3. 实验目的

#### 4. 系统工作原理

##### 	4.1 卷积神经网络层级结构

###### 		4.1.1 数据输入层

###### 		4.1.2 卷积层

###### 		4.1.3 池化层

###### 		4.1.4 全连接层

###### 		4.1.5 Dropout层

###### 		4.1.6 Batch_Normalization层

##### 		4.1.7 激活层

##### 	4.2 训练优化器

##### ​	4.3 系统工作原理

#### 5. 使用工具（有Tensorflow ，Keras 以及 Pytorch三个版本的代码）

##### 	5.1 Tensorflow & Keras

##### 	5.2 Pytorch

### 第三部分 系统实现步骤以及方法

#### 6. 数据预处理以及加载

#### 7.建立模型

#### 8. 训练并保存模型

#### 9. 使用训练好的模型进行预测

##### 	9.1 使用摄像头进行实时识别

##### 	9.2 对测试图片进行批量预测

### 第四部分 结果评估以及问题讨论

#### 10. 结果评估

##### 	10.1 过拟合问题

##### 	10.2 训练问题

***



## 第一部分 环境配置

### 1. ubuntu 与 python虚拟环境的配置

---



操作系统： Ubuntu 16.04

语言版本： Python 3.6.5 （Virtualenv）

需配置前端框架： Keras， Tensorflow-gpu， Pytorch

需配置Python依赖： Numpy， Scikit-learn， matplotlib， opencv， PIL， h5py

<u>***详细的配置方法以及运行指令见项目目录下的README.md文件*</u>**

### 2. CUDA 与 CUDNN 的配置

---



CUDA和CUDNN用来对训练加速，可以提升10倍左右的训练速度

详细安装教程，可能出现的问题以及错误解决见我之前写过的[wiki栏目](http://openbotics.org/wiki/index.php?title=Caffe%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8EOpenCV%EF%BC%8CCUDA,CUDNN%E7%9A%84%E9%85%8D%E7%BD%AE)

内容包含在ubuntu下安装显卡驱动， CUDA， CUDNN以及源码编译安装Opencv 3.3.1， 源码安装Caffe以及Darknet。

### 在环境配置上有问题请联系：hilbertxu@outlook.com

## 第二部分 人脸识别系统的原理以及使用工具

### 3. 实验目的

---



学习对大规模数据进行预处理的方法，以及如何更高效的装载训练数据

学习深度学习框架（keras， tensorflow， pytorch）的使用，如何搭建神经网络模型， 如何使用训练数据训练模型，如何对模型进行苹果

学习如何使用训练好的模型对样本进行预测

学习如何使用训练好的模型对于摄像头中的视频流进行实时识别

### 4. 系统工作原理

---

#### 4.1 卷积神经网络层级结构

我的识别系统使用了迁移学习能力较强的VGG-16网络，其网络结构如下所示：

​		![](/home/kamerider/Pictures/20180228195222196.jpg)	

整个网络可以分成特征提取器和分类器两部分，特征提取器主要包括卷积层，池化层，卷积层用来提取图像的高维特征，池化层用来对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。

![](/home/kamerider/Pictures/20180228194950318.jpg)

##### 4.1.1 数据输入层

​	输入数据是一个Batch的图像数据

​	是一个四维张量,尺寸为：[batch_size, image_size, image_size, image_channels]

##### 4.1.2 卷积层

​	卷积层中通过生成多个随机权重的卷积掩模对图像进行卷积操作来实现图像高维特征的提取。卷积层可以形象的理解为给图片加上滤镜，对于每一张图像，n个卷积核就相当于给原始图片上加上了n种滤镜，可以获取到原始图像的nge不同的feature maps。卷积神经网络中，通过多层卷积操作，可以提取出每一类图像的高维特征。

​	卷积层中每个卷积核(神经元)都与前一层中位置接近的区域中的多个神经元相连，区域的大小取决于卷积核的大小，在文献中被称为“感受野”。卷积核在工作时，会有按照给定的移动步长规律地扫过输入特征，在感受野内对输入特征做矩阵元素乘法求和并叠加偏差量。

![](/home/kamerider/Pictures/132T62633_0.png)



​	在VGG-16网络中全部使用3*3卷积核、2*2池化核，不断加深网络结构来提升性能，其优点有：

（1）多个一样的3*3的卷积层堆叠非常有用 

（2）两个3*3的卷积层串联相当于1个5*5的卷积层，即一个像素会跟周围5*5的像素产生关联，感受野大小为5*5。

（3）三个3*3的卷积层串联相当于1个7*7的卷积层，但3个串联的3*3的卷积层有更少的参数量，有更多的非线性变换（3次ReLU激活函数），使得CNN对特征的学习能力更强。 

##### 4.1.3 池化层

​	池化层一般接在卷积层之后，用于对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。一般我们使用的是MaxPooling，即最大池化：在每一个池化区域中找最大值来代替这个区域的特征。

​						![](/home/kamerider/Pictures/1062917-20161117212026498-272435652.png)	

​	

##### 4.1.4 全连接层

​						![](/home/kamerider/Pictures/webwxgetmsgimg.jpeg)

​	在神经网络中，全连接层的主要作用是分类。当数据是线性可分数据的时候，只需要一层隐藏层就可以实现对数据的分类；而当数据是线性不可分的数据的时候，就需要使用隐藏层来进行分类，可以认为将原始输入数据，在每一层隐含层上做了多个二分类，二分类的个数即为该隐含层的神经元个数。

​						![](/home/kamerider/Pictures/20170713133836450.png)



##### 4.1.5 Dropout层

​	在大规模的神经网络中有这样两个缺点：1. 费时；2. 容易过拟合。对于一个有 N 个节点的神经网络，有了 dropout后，就可以看做是 2^N 个模型的集合了，但此时要训练的参数数目却是不变的，这就缓解了费时的问题。

​	Hinton在2014年发表的论文***Dropout: A Simple Way to Prevent Neural Networks from Overfitting* **中做了这样的类比，无性繁殖可以保留大段的优秀基因，而有性繁殖则将基因随机拆了又拆，破坏了大段基因的联合适应性，但是自然选择中选择了有性繁殖，物竞天择，适者生存，可见有性繁殖的强大。dropout 也能达到同样的效果，它强迫一个神经单元，和随机挑选出来的其他神经单元共同工作，消除减弱了神经元节点间的联合适应性，增强了泛化能力。

​					![](/home/kamerider/Pictures/1667471-8e10d8a8e14a2ef4.png)



##### 4.1.6 Batch_Normalization

​	我在Keras版本的训练代码中并没有加上Batch_Normalization层，在Pytorch版本的代码中，对于每一层卷积层都加上了Batch_Normalization层来加速巡礼那。结果十分显著，在同样地数据，同样地网络结构下，Keras大概需要20此左右的迭代，训练精度才能稳定在98%以上，而Pytorch大概需要7次迭代就可以达到98%以上的训练精度

